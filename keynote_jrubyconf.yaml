---
title: Keynote
speaker: Tom Enebo and Charles Nutter
transcript: |
  Testing one, two, three, four, testing one, two, three, four, testing one, two, three, four
  >> Welcome to eurucamp! That is not safe for work. (Laughing)
  >> So, if you didn't get a hug, yet, then, see Josh on the break. (Yeah)
  >> Welcome. Thank you very much for making it this morning, sorry we're running a little bit behind. As you see, we are a small group, but we are a small group of experts. And, I'm very, very glad and honored to have some of the experts of this awesome Ruby implementation here in the room today. So ... what we'll do is we'll quick off first with a few boring practicalities. Not so boring practicalities, first of all is transcription. All sessions at eurucamp including JRuby Comp will be transcribed as you've probabliard noticed on the right ((Applause)) so thank you very much to our sten nothing for for being here excite's lot of work, so ‑‑ Stenographer ‑‑ so thank you again for being here for us. Apology for the problem with the coffee, we were late running with the coffee this morning, if you haven't got your dose, already, then, 11:15 is the first break, yeah, you have to bear with us for a bit. But I'm sure Tom and Charles' keynote will be sufficiently lively so you won't need additional Cafinitation. Tonight, stick around after JRuby today for the eurucamp keynote, even if you don't have a full eurucamp ticket, you're entitled to stay for the keynote, which is then followed immediately by a party. There are also many other things you can do, in the breaks, tomorrow, that don't necessarily require a ticket, find out at activities at activities.Erurcamp.org. So without further adieu, I would like to invite Charles and Tom to come forward and get ready. (Applause)
  >> Charles Nutter, bear with us a second while we switch over.
  >> So question had the honor of welcoming Tom for three years in a row to Berlin. And, Charles now two years in a row. They will be here for the whole of eurucamp this year, they'll also give a slightly slim version of their talk at your cam, if they make it back from the Berlin beer festival.
  >> Tom Enebo:  That's between the two talks, so there'll be at least one talk (Laughing)
  >> Yes. So, once again, a big honor to have them here, a big round of applause for Tom and Charles (Applause)
  >> Tom Enebo:  Thanks for coming today ‑‑ is this on?  Great, thanks ‑‑ my name is Tom Enebo, I guess we just had introductions so the slide is suddenly redundant.


  >> I'm Charley, thanks.
  >> Tom:  We basically have two branches that anyone cares about on the top is master, it's going to be JRuby 9000 some day. It's going to support Ruby 2.1 maybe 2.2 if development takes a little too long, and we have the 1.7 branch that everyone is using today which is for 1.8 and 1.9 support
  's a 2, but it's experimental. If you do give us feedback on that. Probably when we get back from Berlin we'll put out 117‑point 1 , we have one outstanding issue. And, people don't have do you about 1.7 going away, I can see we can easily say that we'll put out releases for the next year and a half, and actually, it could go on longer, it just depends on whether people are going to cling to 1.9 or willing to actually move towards Ruby 2.1, which I hope everyone will be ‑‑
  >> Charles:  We don't have plans to go beyond 1.9 in the JRuby 1‑7. It would be great place for folks to contribute fixes so we can focus on 9000 but continue to support the 1.7 line.
  >> Tom Enebo:  This is the first time in years that we were able to do multibranch successfully. That was really cool. Thank you (Applause) and so we really wanted to put out 9000 around the end of the summer, or pretty close to now, hand that's not going to happen. We'll talk about some of the to do stuff later, but, things are coming along pretty nicely, but, not quite nicely enough where we want to put out a preview release, we talked about this a lot, and in our ‑‑ from past experiences, when we go and put out a preview relose, it shifts focus on users that the release is around the corner and people stop submitting fixes or reporting bugs against the current version, which is 1.7, so we're not go dog that yet, any ways. What we did instead, we created the GH label the 9000 feedback, you can use RVM or appropriate Ruby installer or get clone a repository, try running your stuff with master, if you actually find an issue, report an issue at 9000 feedback to it, and we promise we'll give you fast feedback and hopefully a fast fix because we want to get 9000 in shape as fast as we can. So, let's talk about 9000, that really is the next version number of JRuby. We'll talk about the new run time. On ineventually named internal representation. So, we wanted to make a new run time because we're tired of working with an abstract syntax tree, wanted something that represented Ruby semantics, more importantly, we wanted something that if a new contributor came to the project and taken a Compilers course at university, they can jump in, the vocabulary's the same, the solutions are the same. And like all software projects, we don't want to rewrite a run time, another time. So this is going to be the last time (Knock on wood) so, in 1.7 today we see this in the top dash box, we go and tokenize the Ruby store and generate an abtract syntax tree, our interpret walks around the tree, our GIT Compiler walks around the abtract tree and ‑‑ now in 9000, we have a few more fazes, we do semantic analysis with we generate a set of virtual machine instructions, not dissimilar from Java byte code but they represent rue we semantics, created ‑‑ Ruby semantics, go through ane a set of optimization set of passes to optimize that code, by the time we get to the bottom layer, we have a very thin interpreter, that doesn't have a ton of logic, hopefully we have a fairly thin set of byte code generaller raptors. Most of the heavy lifting has been done during semantic analysis. So, here's a first look at IR instructions for the source on the left I'll just go over couple of these. So, at instruction zero we character Arity to make sure there's two required arguments, instruction one and two we bind the parameters A and B to the incoming zero and first argument coming in. If we go down to 8, we can see that we're calling the plus method on the receiver A and we're providing it the variable C, pretty simple stuff. We do a whole bunch of optimizations, again, if you've taken a Compilers course at university, which I haven't, we do things like dead code eliminations, I'll show you some examples of that in a bit. We can propagate constants, so, if a variable contains something that doesn't change, we'll just move it to where it's used so we don't have to indirect it through the variable, we can do method in‑lining, pull the entire body of a method back to where it's called so we don't have to actually set up and invoke a method, and it's all done through a plugble Compiler pass architecture. Here's two optimization passes done, you can see that we went from about 10 instructions down to six. We don't use B so, we got rid of that, it doesn't use any blocks anywhere, so we eliminated that, at line 6 on the left, C equals 1, it's a constant so we just push that on the right to line 5 where we call A plus one now instead of A plus C. In general there's a lot of explicit instructions in this instruction set, primarily so we can use dead code elimination to get rid of them. We do this, because in the old world we would of had a very cheep inexpensive check to say, oh, was there a closure to this method?  Well, if there was or wasn't, it was a cheap check, it didn't cost a lot, if you the that a few billion times you can see it add up, we call this death by a thousand cuts, when ever we profile JRuby we never see a culprit, we see a thousand culprits, nothing really appears to be making any serious performance impact. And it also kind of goes along with this Meme of less code more fast, JVM likes working with nie methods, it can do a lot more optimizations with that, if we can strip out unnecessariry work, we're going to get faster code. So, I'm going go through a couple of examples why I they haveR is really cool as an emme minister, one of the things IR is doing now, in about 90 percent of the cases it can statically determine which ‑‑ how super is going to resolve before we execute, this means we don't have to have the special super logic every time that's there because it's been converted to a regular method call. It also means we don't have to store any data in our run time in special logic because it's gone, because it is just a regular method call now we can do all the same optimizations that we could do with ordinary methods. And, again, this is another example of getting rid of some small overhead that we had. And mostly ‑‑ just because it was funny, I guess. We knew, we knew that when we turned off the old run time that there was going to be some things on the edges that broke, we were okay with that because a little bit of breakage is good motivation to actually fix the breakage. So, some stuff did break, in particular, I didn't realize that set trace Func was only an old run time, so, when we passed dash, dash Debug as a flag, then all of our methods get wrapped in another class that emits these trace instruction events, ‑‑ trace events, and also in some other places in the old run time had some conditionals, so, if Dbug was on, then it would start emitting trace events, so how to solve this in the new world?  Create a new instruction called "trace" it only took a few minutes, then just had to find the places and IR builder where we're generating the instructions and put the trace instructions there, and the add benefit is, this is going to work in the Jit, in the hold run time we disabled the Jit when you actually had debug on. So ... cool ... of last one of IR is several years old, we've been working on it for years, but the JIT is a newer edition, we started to realize though we had valid representation of Ruby semantics, the JVM had some requirements that we just didn't quite line up with, so I'm going go through one example, and I'm not going to show Java byte code or IR instructions because this will work fine with Ruby in general. So, this was the original reported code, I'm just going to use the code thin et on the right with the more explicit begin ensure (Snippit) it's the same code and maps better to the rest of the example. This is a really simple method, you save Osync instance variable, you call black and an insure block to make sure you restored the original value. So, when this IR gets translated to Java, it did this, essentially, now, if you know Java, you know that that doesn't work. And that's because in Java, try and finally are both different variable scopes where they are not in Ruby. So, then, Charley realized this problem right away and he's like, well, I'll work around it, I'll just go and set the local variable to Nil at the top, in fact he did it to all local variables as a default thing, very simple to work around the issue. Problem solved ... since now we have the declaration above, so now it satisfies Java's requirements. So, that didn't work (Laughing) but, it should have worked and it didn't work because we do dead code elimination. So, I said, if you can't reach code then it eliminates it, if you can't see a visible effect, then it's going to eliminate anything that's not visible, and to maybe make it a little more concrete, if we have two variables that are redundant assignments happening right after each other, and there's no chance of anything happening between those two statements, we just get rid of the first one. Which, brings us back to here and we blow up. So ... to work around this, I had to talk a little bit about basic blocks when we go in and compile any unit of code in IR, we generate a series of these blocks. And, they're actually a graph. Each block can contain many instructions in it. Maybe to make this appear to be a little more Graf, I'll add a rescue in here, so, we'll just execute the code in one, go to two if will's no exception then we'll jump down to four, if we raise an exception then we'll go through three and four.
  >> Each of the arrows is transition from one block to another, how they depend on each other's data and the flow of the program.
  >> Tom Enebo. This is a basic control flow graph. If we go through this example again and try to figure out how to solve the problem so dead code elimination doesn't get rid of Osync and block one, we can add a dummy edge to any rescue block, then when DCE runs it will realize that it has to Osync has to be live in basic block one because it has a path to three and it's used. So, this is pretty simple way to solve the problem. This might not be our ultimate solution, but, it was really easy to go and figure out how to solve this. So, these are just touchy feelly feelings for me.  I love IR, it's made the project a lot more enjoyable to work with. And mostly because it's a lot easier to reason with, the problems we have and localize them. And, when ever we have a problem like this, we can talk to Saba, Sastry, he originally created I R and he has a PhD in running static optimizing compiling for Java. Say oh, we have the problem, he'll goes oh, you do this solution, this solution or this solution, so that's really cool, there's known solutions to every problem we have.
  >> Charles Nutter:  I want to emphasize all the fixes we had along the way, inserting the Nil assignments, cleaning up edges, dead code eliminations nothing requires changes to the instructions or the Compiler, these are bits of codes we can write, making modification to the graph, juggle some instructions around and we have the modified code. Makes it a lot simpler to iterate small optimization and adjustments to the code without having to change the Compiler, like we used to. All right, now it's up to me I'll take on my section here. So I want to talk a little bit about the big amount of work I've been doing in the past four to five months, little background here, JRuby was origin fallly based on 1.6 when it started out in 2001 ‑0 2 or so Tom helped with updating it to Ruby 1.8, when we finally got to JRuby 1.0 that's what we supported 1.6 or 5 something like that, Ruby 1.9 comes along and changes how strings and IO works and introduced character encoding and Trans coding, initially we needed to get basic things working, so we ported parts of this and tried to leverage as much as possible from the JVM, so that, things like the regular expression engine, that was a no‑brainer we had to get that ported, the coding tables had to be ported, some string logic. So, if you look at how IO is actual limb meanted in MRI, it's ‑‑ implemented in MRI it's a very thin wrapper around a file descriptor, all the C level functions would you use to manipulate a file descriptor are mapped right up to the IO level, buffered reads, unbuffered reads, selects, all of that stuff, it's kind of a one to one mapping there, the JVM doesn't give a direct way to access file descriptors and native functions for it, gives a different abstract channel, the unbuffered raw reads and rights from a file descriptor, so initially what we want today and what worked okay for a while was to just emulate all of those Lipc operations on top of the channel. Looked kind of like this, up through JRuby 1.7 releases our IO object wrapped a channel stream, equivalent to a file star at the C level, if you're familiar to C, which wrapped a five channel descriptor which emulated all the five describe to operations you might do. And a channel and buffering inside there, and this worked okay for us up through 1.7 so, JDK also has some trance coding stuff we can use, but the problem S. you also have to go to and from a character array. A UTF‑16 character array. That's what the JVM uses internally so if we wanted to trance code to UTF to SHFJI if we had to go through character array in the middle ‑‑ it wasn't ideal, but it did work, and allowed us to have trance coding basically functional up to 1.7. Now, obviously there's some problems with this approach, first of all not all encodings were supported by the JDK, some of those we had to punt on and say EMEX Mul is probably not the most important one for us to have, but things like ISO 85913 that some eastern European countries need to use and we get bug reports about that. That's one problem, we had to import some encodings over to the JDK, there's obviously a lot of wasted work pacesing through that character array and doing two trance coding for every trance coding operation. And finally, the last straw here was that we could have a failure in the trance coding from the character array back to bytes, but, at that point, we've already, so far away from the original content, we can't say it was this character at this index that caused the problem, there was no way to present the right error to the user, so that kind of forced us to take a different approach.
  >> Tom Enebo:  There was also multiple byte substitution wasn't allowed with Java.
  >> Nicholson:  We were able to work around that, it was limited on what we were able to do a byter A byter A trance coder (Nut in the) and then to compound things there were also problems with IO in the way we had it impresented .
  not all channels on the JVM can be selected, very importantly, standard IO channels can't be selected and process, sub process channels can't be selected, which we got continuous reports about and all sorts of way to work around that were not quite as good as we'd like. The buffering logic, also, didn't match MRI, so performance wise and behavior wise, it was hard to make it look the same. And, in MRI, all of the trance coding that happens when you read from IO happens against those internal Io buffers. In JRuby, the way we were doing it was, we do the raw read and get a string in hand and trance code the string and give that to you, which is obviously not as efficient .
  there were also too many edge pages to miss, lots of little behavior tweaks and oddity in the MRI code that was unimpossible for us to emulate or clean room this without years of constantly testing all the educations, so it was hard to get a fully functional system that way. And then just incomplete file descriptor representation, like I mentioned the selections, couldn't change buffering, couldn't access raw file control operations and so on. So, if I show you what IO looks like within MRI, you can see the structure is very different from what we were doing in JRuby. And in order to walk through this a little bit, we'll have J actually do this for us. (Chuckles) we do our IO read call in Ruby somewhere, we check to see if there's decoded character for in the buffer that we can just pull right out and present to the user, if there's nothing there, it's empty, the next thing we do is go over to the read buffer and see if we have untrance coded raw bytes that were offered off the wire that we could give to the user, assuming there's nothing there, we go over to our file descriptor and we get a blob of raw bytes out of it and carry them back and put in the read buffer, if we don't need to do any trance coding, if we're UTF 8 internally and UTF 8 externally we can just bring it back to the user right at this point. However, we'll look at the trance coding case, so we take the bytes over and the trance cored works on it far while and stuffs it into another buffer, the character buffer, and this point we can bring the bytes back as a string and leave them there for the user to pick up. (I think this deserves a round of applause (Applause)
  >> Nut Charles:  Do as many presentations as I do ‑‑ ... it works really well for MRI internally after reading through some of the code, started to understand how these pieces fit together, and I decided I'm just going to port the remaining pieces of IO and trance coding logic that we didn't already have. The porting helption guarantee correctness, it makes it possible for us to map ‑‑ map everything back to MRI as well, and, it kind of forced me to bring up the real file descriptor, bring up real low‑level IO operations to the user, so now we can have select on all different Io channels, we can do all the file control, TTY operations and so on.
  >> Tom:  It's probably worth mentioning as well that the coverage is not fantastic for this stuff. So ...
  >> Charles:  The available test that we have, the JRuby project runs fiver or six different Ruby test suites, Ruby Spec, Rubico in, our own JRuby sweet and a couple others, even with all those cases there's still a steady stream of education bugs that we had to find some way to fission.
  >> Tom:  Anything hitting a resource is always underspecified.
  >> Charles:  It's hard to do good tests for IO operations. So how's it looking. It is landed on master, IO performance is about what it was before, a little bit lower maybe, this is all still a naive port directly from the C code, we can do a lot of unCfyinng to make it better, it should be better than JRuby 1.7. Trance coding is faster in most cases and it now matches MRIs trance coding exactly. All of the operations work, there's only a handful of tests that don't pass, so really happy with how the trance coding stuff has worked out. And also important the semantics of all these IO operations and what you would expect to happen, should match MRI exactly, this may be our final escape from IO in trance coding bug reports, at least as far as they relate to compatibility. (Knock on wood)
  >> Yes. We also have a much better understanding of how trance coding and IO work in Ruby, easier to fix things help MRI improve it and work with the Ruby team more closely going forward I'll say a few things where the JIT status is, again, a little background here, up until JRuby 1.8 it just interpreting, we only (Up until 1.8) good enough was actual leisler than 1.87 at the time, not as good as we like. In JRuby 1.1 we added a JVM byte code JIT, that was the first time we were compelling faster than C Ruby, and we've continued to make small opt my sixes, small improvement to that JIT over time (Optimizations) it started to get more and more difficult, dog our compilation against AST limited much flexibility we had in those instructions, the optimizations started to stack up and got really ugly. It was obvious that we needed something better. That's where IR comes along. So, the nice thing about the JIT now is that because the IR does most of the heavy work of figuring out low‑level semantics of the code, the JIT is very simple. Every instruction that's in the IR only has two or three JVM byte codes that go along with it. Whereas AST from the old Compiler would have dozens of byte codes that would have to be emitted, a lot more work done at the JIT level, about 75 percent, right now, of the instructions will JIT down to JV and byte code, which sounds like a lot, but the last few instructions kind of keep a lot of things compiles at the moment, maybe 20 percent of code will actually compile in J JV and byte code in master, in the next month I should be able to get it to a hundred percent. What does JIT, the performance looks good without any optimization work, any one‑off passes like we did in the old Compiler, I think this is going to ramp up extremely fast once the JIT is hundred percent, we should make the opt my six and pass JRuby 1.7 performance and far beyond that.
  >> Tom:  Okay, so,i've been working on some tooling, as a proof of concept. The thing that reinvigorated my desire to work on this tooling was MRIs Ob space only jewel, allows you to dump part of all of your heap to a Json screen, some person named Qwerky made a viewer, as you can see, it's pretty primitive output, I think this was just something that Kowchi added for work he was doing now people are finding ways to use it. There's tons of memory analysis tool in Java have a ‑‑ I'm showing you Jap, which is probably the oldest long, it willowed a heap and generate a web App if JIT is part of Java, if you're a JRuby user, you can use Java analysis tool to find memory leeks, but sometimes it's a little painful, so if you know you're working with a string, you'll find the Lorg Jruby string ‑‑ you know you're leaving strings, but sometimes it's much less clear because Java memory maps don't show you JRuby. Someone showed us several years ago ‑‑ called fast hat. If there was a Ruby string instant it would print a nice pretty version of the Ruby string and the size and that was great. That was a big step up. Unfortunately I couldn't get it to run because it was really a fork of J hat, like the same class, same packages, and that really doesn't work well. But, to give you an idea of just how bad this can be, let's say you are look at a Ruby string, so we look at this in J hat and we're look, oh, it has a Meta class, oh, value, let's see what the value is, it's in a byte list, that makes sense that Ruby strings are in bytes, oh, what's the byte, oh, it's a primitive byte already, oh ... okay ...
  >> Charles:  Really useful
  >> Tom:  What is that string?  It makes sense it will not display as a string?  Java, a byte array could be for represent senting any characters or none I'll be honest, I've only beenment on this the last week, I have a command line tool that will take a Java heap process it into an IRB console or generate a Json dump, and then I made a web viewer yesterday, so, here I'm generating a Json dump, and you can see it took 33 seconds to process 600,000 Java objects, almost 5700 Java classes that was for doing JRuby‑e "gets" so it's kind of slow. But, by the time I was done, I was able to extract 371 Ruby classes and almost 12,000 Ruby instances .
  >> Charles:  That's mostly Ruby gems booting up, that's what it is.
  >> Tom. Yeah. So let's see, demo. So, here's all the classes, right now I only have the count. But, it displays way better than having ‑‑
  >> Charles:  Go back to the Ruby gem requirements ‑‑ oh you is a good one?
  >> Tom:  I'm going to show symbol first. Yeah, recursive key, a lot better than a bunch of ordinal values. Let me go back up to gem ... platform.  I will admit there's still some holes in this. But now I can see the instance variables, that's pretty cool. And I can see that the OS for this was Java, as you'd expect from a JRuby instance. And that's about all I have at the moment, but, this will be able the show full stacks, be able to do references and what other things are referencing the same object, every single Ruby object that's pure Ruby will actually show it's complete size and what's in it.
  >> Charles:  Another cool thing about this if we ‑‑ if we're able to keep the Json close to what MRI is emitting some of the same tools doing memory analysis will work for both JRuby and MRI, hopefully we'll be able to match up with MRI
  Tom Tom:  I would like to think it would easily work for MRI if they needed to dump the same thing. It needs to be sped way, way up, most people have multiple Gig heaps, they don't want to make a Json stream in two days. Then I was just hacking lock a monster, don't go and look at that code. But, I learned a lot, so ...
  >> Charles:  I think it's a pretty good set of tools for about a week's worth of work.
  >> Tom:  That heap processing stuff is just ... Eeee ... it's not fun. And just filling it out bayically, the last point is maybe that we introduce a library in JRuby that allows us to keep track of memory layout. Because we don't have the advantage of just being able to call some jay have method to say give me the instance variables you have to look at the Java object figure out the class and slowly rip that thing apart and we don't store everything in the same way over time we're going to drift. So ...
  >> Charles:  All right, so we'll do a couple slides on what's left to finish up 9000. We oar not exactly sure what the time frame is to finish it. But things are look got. The JIT, as you expect, a hundred percent of the instructions working, I don't think that's going to take more than a couple weeks once I get home
  's minor thread safety issuessh optimization passes and things like, that we need to run against the IR that we don't necessarily want the run for the interpreter, so if we're interpreting at same time that we're Jiting, we don't want to step on each other toes, just a little bit of clean up required for that. And right now, the JIT only supports Java 7 and higher, because it's using invoked dynamic for everything, I need did another version that will work without invoke dynamic so it can run on Java six, Android and so on.
  >> Tom:  Hopefully the thinness of the byte code generator ‑‑
  >> Charles:  Should be easier than the old Compiler. In the IR we want to continue exploring unboxing explorations, right now ever time a number comes out of an operation in JRuby we have to create a fix N mum or rue my wrap to ‑‑ it's more expensive in MLRI where it's specially tagged and specially structured pointers, we've been looking at early optimizations to remove all of those objects, use raw primitive long operations, raw primitive doubles, which has sped things up many, many time in our experiments, we mostly just need to fix the correctness here and we can probably get numeric math almost up to Java levels in certain scopes. There's a lot of conditional old run time states, old JIT, old code that's not going to be used for the new IR run time, and we oar slowly finding those pieces that are dead removing them from JRuby.
  >> It will speed up our run time.
  >> Right. Smaller and speed things up. On the cam pattability side, it's almost entirely functional, there's a few inusual test in the suite we're working to pass, refinalments are not implemented yet, mostly going to be minor changes to IR and a little bit of work in the JIT then should be pretty functional. The frozen spring optimization introduce in the 2.1, is partially there, but the IR doesn't really flag those as optimizeble operations yet. Filling out the rest of the missing methods from Ruby 2.1. Miscellaneous things, the API that we present to JRuby extension writers is very likely going to break in subtle ways in 9000, we're going to keep it to a minimum and help people adjust to new APIs, we want to know what the breakages are and test out of the libraries now.
  >> We're going to back port those APIs to 1.7.
  >> If you're on JRuby 1.714 plus it'll be the same AI as Ruby 9000.  I want to get all the repaining IO and trance coding tests to pass .
  this is a reachable goal, I think at that point it will be the only other imMr. Mennation that is complete in terms of IO and trance coding, it would be nice not to have the bug reports anymore. And Tom is working on the new parser.
  >> It's about ten percent faster, in branch right now, maybe 20 percent, it's unafraidble due to Evals, there's too many Evals.
  >> Charles:  That's about all we V. hoping we have time for questions, we're really excited about where JRuby 9000 is right now. It's a little further behind than we like, but it's still only a month or two, maybe three past where we originally planned to release it. We're hoping to start testing it out try JRuby master and we'll take it from here, thanks very much for coming out today. (Applause)
  >> Tom:  You can talk to us all day long, all weekend for that matter. But we have about five minutes, maybe, for questions.  ‑‑ I guess we did a good job.
  >> From the floor:  You mentioned if you're using Ruby compact 2.0, it's not recommend for production ‑‑ we're doing that, can you state which are some of the issues.  I think that we have service that might need to be in production.
  >> Charles:  The question was about Ruby 2.0 mode in 1.7. We added a mode, we added some of the 2.0 stuff, it was still experimental to play with, it didn't recommend in production. And the case you have is that you need some 2.0 features in production and you're using JRuby. Correct?
  >> Yes.
  >> Charles:  We're willing to accept patches for 2 on the other 0 behavior specific things that are missing stuff like prePen and refinements are too innovative to put in 1.7 but other stuff weed be willing to do. Honestly the best thing is going to start trying out JRuby 9000 and see if it works for your App so we can finish it up and make sure it's ready for your production system as soon as possible
  Tom:  There's a whole class of key word arguments errors, if you're using key word arguments and it works for you, we're probably not going to make it work any better than the 1.7 branch.
  >> If I remember, that was the case, the key word arguments.
  >> Charles:  Give it a try with the newest release JRuby is .7, we'll put the next one out. If there's specific things that you can let us know, and if it looks feasible, we'll work with you to try and fix stuff. But, JRuby 1.7 is a 1.93 compatible implementation.
  >> Tom:  On master we have no actual invocation key word argument sort of indication and tests, only like if you call method.Arty you get some ‑‑
  >> Charles:  Behaviorally it looks a lot better on master now.
  >> Are there many issues for loping in the master branch, that, you know, other people could jump in and help with. Or is it all fairly sophisticated that last 20 percent ‑‑
  >> Is there low‑hanging fruit that folks can jump into or more sophisticated stuff. Definitely a lot of low‑hanging fruit . Probably the easiest way the find that is take a look at Ruby specs we have tags, MRI tests we have excluded, very easy to look in the directors, find features from MRI that aren't passing, the first step is to figure out why it's not passing, that's where we can always use help. Maybe the implementation of the fix can be come plait, but having fuel folks try it out saying this is the reduced case, then it's a day's worth of work if almost every case.
  >> Tom:  If you look attest MRI excludes there's a whole list of tests that we don't pass. Someone did this a long time ago, they wrote a little reflective am that printed out ‑‑ if you ran it against MR ism and JRuby you'd be able to make a Dif and see which methods are missing.
  >> Within thing we introduce in the JRuby 1.7, we have a sort of small, but growing kernel of Ruby Code used to impresent JRuby itself. A number of IO operations, some string operations are actually written in Ruby for JRuby now. If there's a missing met we're happy to take a Ruby implementation of that and throw it into the Ruby kernel. It'll get ported into native code, others we'll find other ways to implement, getting the functionality will first is the key.
  >> You tweeted that you ‑‑ there are some people that heard your cries regarding start up time can you say a if I words about that.
  >> You're the forty person to say you tweeted about the start up fixes.  I talked to JVM folks I was at the JVM summit two days ago in San Francisco.  I heard lots of different solutions. One of them Java 9 may include a way of packaging up your application with just the parts of the JVM you need and precompile down to native binary, this is work being done, ahead of time this is your application binary, the JVM guys themselves are interested in ahead of time compilation cashing some compiled low and speeding up low level Compilers too. Then, as ‑‑ maybe we'll hear a little bit from the Truffle stuff, the graph and Graal, new compiler framework that Oracle is work on, has a way of building pre‑compiled statically combined binary that starts up as fast as MRI, it's fairly limited to what libraries it can access, it doesn't have reflective capabilities and can't run JD and byte code, but for a small application it would be very fast to have that sort of built ahead of time of the so there's a lot of stuff coming. For the short term, two or three different JVM engineer from Oracle asked me to send our worth start up cases to them so they can look at what they're tuning wrong or what they can do to speed up the initial boot time.  I think we'll find something very soon that can at least have it and maybe better. Is that about it?
  >> These about it. All right, great, thanks a lot guys ( applause)
  
